{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Section 5.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aravindkumar-Rajendran/EVA/blob/master/Section_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SJyVpgSxHt4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Add, BatchNormalization\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlEUplvoxKAT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6Y9Va-xxMXG",
        "colab_type": "code",
        "outputId": "fbf52280-7d61-4d51-874b-0c6e839a4c38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "print (X_train.shape)\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(X_train[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f5861dc2860>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRfiBoAg/EBThB4Ii/EBQhB8I6v8AG8x2aarNGp8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxDZxPhhxOgO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HzMqbTnxQQW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LdYiW6ixR9e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train[:10]\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFR0F9j0xVp2",
        "colab_type": "code",
        "outputId": "b6b284a2-3d4e-41a9-910f-3ced56306f44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "Y_train[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSgA6abPOEcy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Image Normalization\n",
        "\n",
        "imax = 1.0\n",
        "imin = 0.0\n",
        "for i in range(0,len(X_train)):\n",
        "    new_min = X_train[i].min()\n",
        "    new_max = X_train[i].max()\n",
        "    if new_min!=0.0 or new_max!=1.0:\n",
        "        X_train[i] = X_train[i] * ((imax - imin) / (new_max - new_min)) + new_min"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDpXf4YQxXRm",
        "colab_type": "code",
        "outputId": "44c0fe85-ad8b-4d41-8ee0-5bfd9bd2421d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1644
        }
      },
      "source": [
        "from keras.layers import Activation\n",
        "from keras import regularizers\n",
        "model = Sequential()\n",
        " \n",
        "model.add(Convolution2D(16, 3, 3,kernel_regularizer=regularizers.l2(0.01), input_shape=(28,28,1))) #26\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(32, 3, 3, kernel_regularizer=regularizers.l2(0.01))) #24\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(10, 1, 1, kernel_regularizer=regularizers.l2(0.01))) #22\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))#11\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, kernel_regularizer=regularizers.l2(0.01)))#9\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, kernel_regularizer=regularizers.l2(0.01)))#7\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, kernel_regularizer=regularizers.l2(0.01)))#5\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, kernel_regularizer=regularizers.l2(0.01)))#3\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(10, 4, 4))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), kernel_regularizer=<keras.reg..., input_shape=(28, 28, 1...)`\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), kernel_regularizer=<keras.reg...)`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1), kernel_regularizer=<keras.reg...)`\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:37: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:43: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (4, 4))`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 16)        160       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 26, 26, 16)        64        \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 26, 26, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 26, 26, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 32)        4640      \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 24, 24, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 24, 24, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 24, 24, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 24, 24, 10)        330       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 10, 10, 16)        1456      \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 10, 10, 16)        64        \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 10, 10, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 10, 10, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 8, 8, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 8, 8, 16)          64        \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 8, 8, 16)          0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 8, 8, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 6, 6, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 6, 6, 16)          64        \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 6, 6, 16)          0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 6, 6, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 4, 4, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 4, 4, 16)          64        \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 4, 4, 16)          0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 4, 4, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 1, 1, 10)          2570      \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 1, 1, 10)          40        \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 1, 1, 10)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 16,604\n",
            "Trainable params: 16,360\n",
            "Non-trainable params: 244\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2IicGJ4x3Be",
        "colab_type": "code",
        "outputId": "cf7ea473-9b1a-4de1-ca53-2483b04b31ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4614
        }
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "def scheduler(epoch, lr):\n",
        "  return round(0.003 * 1/(1 + 0.319 * epoch), 10)\n",
        "\n",
        "filepath=\"weights-improvement.hdf5\"\n",
        "best_model = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.003), metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, Y_train, batch_size=128, epochs=40, verbose=1, validation_data=(X_test, Y_test), callbacks=[LearningRateScheduler(scheduler, verbose=1), best_model])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/40\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
            "60000/60000 [==============================] - 11s 177us/step - loss: 0.8136 - acc: 0.8525 - val_loss: 1.8510 - val_acc: 0.4064\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.40640, saving model to weights-improvement.hdf5\n",
            "Epoch 2/40\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.3372 - acc: 0.9174 - val_loss: 0.1653 - val_acc: 0.9780\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.40640 to 0.97800, saving model to weights-improvement.hdf5\n",
            "Epoch 3/40\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.2842 - acc: 0.9308 - val_loss: 0.1874 - val_acc: 0.9656\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.97800\n",
            "Epoch 4/40\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.2526 - acc: 0.9370 - val_loss: 0.1370 - val_acc: 0.9789\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.97800 to 0.97890, saving model to weights-improvement.hdf5\n",
            "Epoch 5/40\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.2284 - acc: 0.9422 - val_loss: 0.1277 - val_acc: 0.9777\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.97890\n",
            "Epoch 6/40\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.2153 - acc: 0.9427 - val_loss: 0.1312 - val_acc: 0.9745\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.97890\n",
            "Epoch 7/40\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
            "60000/60000 [==============================] - 7s 112us/step - loss: 0.2008 - acc: 0.9465 - val_loss: 0.0846 - val_acc: 0.9888\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.97890 to 0.98880, saving model to weights-improvement.hdf5\n",
            "Epoch 8/40\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
            "60000/60000 [==============================] - 7s 112us/step - loss: 0.1922 - acc: 0.9456 - val_loss: 0.0894 - val_acc: 0.9874\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.98880\n",
            "Epoch 9/40\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.1862 - acc: 0.9459 - val_loss: 0.1527 - val_acc: 0.9655\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.98880\n",
            "Epoch 10/40\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.1769 - acc: 0.9485 - val_loss: 0.1156 - val_acc: 0.9771\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.98880\n",
            "Epoch 11/40\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.1712 - acc: 0.9484 - val_loss: 0.0717 - val_acc: 0.9901\n",
            "\n",
            "Epoch 00011: val_acc improved from 0.98880 to 0.99010, saving model to weights-improvement.hdf5\n",
            "Epoch 12/40\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.1648 - acc: 0.9502 - val_loss: 0.0694 - val_acc: 0.9896\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.99010\n",
            "Epoch 13/40\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.1623 - acc: 0.9497 - val_loss: 0.0641 - val_acc: 0.9911\n",
            "\n",
            "Epoch 00013: val_acc improved from 0.99010 to 0.99110, saving model to weights-improvement.hdf5\n",
            "Epoch 14/40\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.1549 - acc: 0.9516 - val_loss: 0.0661 - val_acc: 0.9900\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.99110\n",
            "Epoch 15/40\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.1539 - acc: 0.9499 - val_loss: 0.0654 - val_acc: 0.9891\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.99110\n",
            "Epoch 16/40\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0005185825.\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.1520 - acc: 0.9506 - val_loss: 0.0618 - val_acc: 0.9904\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.99110\n",
            "Epoch 17/40\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.000491481.\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.1486 - acc: 0.9515 - val_loss: 0.0568 - val_acc: 0.9923\n",
            "\n",
            "Epoch 00017: val_acc improved from 0.99110 to 0.99230, saving model to weights-improvement.hdf5\n",
            "Epoch 18/40\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0004670715.\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.1423 - acc: 0.9523 - val_loss: 0.0602 - val_acc: 0.9905\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.99230\n",
            "Epoch 19/40\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0004449718.\n",
            "60000/60000 [==============================] - 7s 112us/step - loss: 0.1412 - acc: 0.9530 - val_loss: 0.0576 - val_acc: 0.9910\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.99230\n",
            "Epoch 20/40\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.000424869.\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.1407 - acc: 0.9523 - val_loss: 0.0548 - val_acc: 0.9920\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.99230\n",
            "Epoch 21/40\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.0004065041.\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.1384 - acc: 0.9536 - val_loss: 0.0528 - val_acc: 0.9927\n",
            "\n",
            "Epoch 00021: val_acc improved from 0.99230 to 0.99270, saving model to weights-improvement.hdf5\n",
            "Epoch 22/40\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 0.000389661.\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.1389 - acc: 0.9525 - val_loss: 0.0515 - val_acc: 0.9920\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.99270\n",
            "Epoch 23/40\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.0003741581.\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.1324 - acc: 0.9533 - val_loss: 0.0543 - val_acc: 0.9911\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.99270\n",
            "Epoch 24/40\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.0003598417.\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.1303 - acc: 0.9549 - val_loss: 0.0526 - val_acc: 0.9909\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.99270\n",
            "Epoch 25/40\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 0.0003465804.\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.1290 - acc: 0.9545 - val_loss: 0.0499 - val_acc: 0.9926\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.99270\n",
            "Epoch 26/40\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 0.0003342618.\n",
            "60000/60000 [==============================] - 7s 113us/step - loss: 0.1279 - acc: 0.9542 - val_loss: 0.0525 - val_acc: 0.9914\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.99270\n",
            "Epoch 27/40\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 0.0003227889.\n",
            "60000/60000 [==============================] - 7s 112us/step - loss: 0.1280 - acc: 0.9541 - val_loss: 0.0516 - val_acc: 0.9911\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.99270\n",
            "Epoch 28/40\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 0.0003120774.\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.1286 - acc: 0.9541 - val_loss: 0.0577 - val_acc: 0.9891\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.99270\n",
            "Epoch 29/40\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 0.000302054.\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.1250 - acc: 0.9548 - val_loss: 0.0471 - val_acc: 0.9923\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.99270\n",
            "Epoch 30/40\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 0.0002926544.\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.1277 - acc: 0.9527 - val_loss: 0.0445 - val_acc: 0.9931\n",
            "\n",
            "Epoch 00030: val_acc improved from 0.99270 to 0.99310, saving model to weights-improvement.hdf5\n",
            "Epoch 31/40\n",
            "\n",
            "Epoch 00031: LearningRateScheduler setting learning rate to 0.0002838221.\n",
            "60000/60000 [==============================] - 7s 112us/step - loss: 0.1225 - acc: 0.9554 - val_loss: 0.0446 - val_acc: 0.9935\n",
            "\n",
            "Epoch 00031: val_acc improved from 0.99310 to 0.99350, saving model to weights-improvement.hdf5\n",
            "Epoch 32/40\n",
            "\n",
            "Epoch 00032: LearningRateScheduler setting learning rate to 0.0002755074.\n",
            "60000/60000 [==============================] - 7s 112us/step - loss: 0.1234 - acc: 0.9558 - val_loss: 0.0455 - val_acc: 0.9930\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.99350\n",
            "Epoch 33/40\n",
            "\n",
            "Epoch 00033: LearningRateScheduler setting learning rate to 0.000267666.\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.1207 - acc: 0.9559 - val_loss: 0.0426 - val_acc: 0.9943\n",
            "\n",
            "Epoch 00033: val_acc improved from 0.99350 to 0.99430, saving model to weights-improvement.hdf5\n",
            "Epoch 34/40\n",
            "\n",
            "Epoch 00034: LearningRateScheduler setting learning rate to 0.0002602585.\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.1228 - acc: 0.9544 - val_loss: 0.0459 - val_acc: 0.9914\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.99430\n",
            "Epoch 35/40\n",
            "\n",
            "Epoch 00035: LearningRateScheduler setting learning rate to 0.00025325.\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.1181 - acc: 0.9561 - val_loss: 0.0409 - val_acc: 0.9939\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.99430\n",
            "Epoch 36/40\n",
            "\n",
            "Epoch 00036: LearningRateScheduler setting learning rate to 0.0002466091.\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.1202 - acc: 0.9541 - val_loss: 0.0437 - val_acc: 0.9928\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.99430\n",
            "Epoch 37/40\n",
            "\n",
            "Epoch 00037: LearningRateScheduler setting learning rate to 0.0002403076.\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.1189 - acc: 0.9550 - val_loss: 0.0413 - val_acc: 0.9936\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.99430\n",
            "Epoch 38/40\n",
            "\n",
            "Epoch 00038: LearningRateScheduler setting learning rate to 0.0002343201.\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.1165 - acc: 0.9566 - val_loss: 0.0436 - val_acc: 0.9930\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.99430\n",
            "Epoch 39/40\n",
            "\n",
            "Epoch 00039: LearningRateScheduler setting learning rate to 0.0002286237.\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.1170 - acc: 0.9559 - val_loss: 0.0495 - val_acc: 0.9912\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.99430\n",
            "Epoch 40/40\n",
            "\n",
            "Epoch 00040: LearningRateScheduler setting learning rate to 0.0002231977.\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.1165 - acc: 0.9555 - val_loss: 0.0447 - val_acc: 0.9924\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.99430\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f58a1312208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLxlW9ufyQiO",
        "colab_type": "code",
        "outputId": "bbd3f21b-d08b-4ea4-dcaf-02819d6aca89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.04467879530787468, 0.9924]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6aAjguK3LQV",
        "colab_type": "code",
        "outputId": "9a726bfa-d2eb-4064-f2ca-c6032429b520",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "lab = []\n",
        "res = model.predict(X_test[0:10000])\n",
        "\n",
        "for i in range(0, len(res)):\n",
        "    imax = res[i].max()\n",
        "    for j in range(0,len(res[i])):\n",
        "        if res[i][j]==imax:\n",
        "            res[i][j]=1\n",
        "\n",
        "        else:\n",
        "            res[i][j]=0\n",
        "\n",
        "    if  not list(res[i])==list(Y_test[i]):\n",
        "        lab.append(i)\n",
        "\n",
        "print(i)        \n",
        "print(lab)     \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9999\n",
            "[115, 321, 412, 445, 447, 625, 716, 740, 947, 956, 1014, 1039, 1226, 1242, 1393, 1444, 1527, 1530, 1790, 1901, 2018, 2035, 2130, 2135, 2266, 2293, 2326, 2369, 2447, 2454, 2462, 2514, 2597, 2654, 2930, 2938, 3030, 3289, 3422, 3558, 3762, 4007, 4176, 4201, 4497, 4620, 4639, 4699, 4860, 5937, 5955, 5997, 6555, 6571, 6576, 6597, 6605, 6625, 6651, 6755, 6883, 8061, 8326, 8408, 8502, 8527, 9620, 9634, 9638, 9642, 9664, 9679, 9729, 9792, 9811, 9839]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UB1hvvSiL8m7",
        "colab_type": "code",
        "outputId": "00ca1d71-cfab-476a-b4f2-c16ca58d76e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        }
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(X_train[1])\n",
        "c = 0\n",
        "plt.subplot(5,5,25)\n",
        "for i in lab:\n",
        "    plt.subplot(5,5,c+1)\n",
        "    plt.imshow(X_test[i])\n",
        "    if c==24:\n",
        "        break\n",
        "    c+=1"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/figure.py:98: MatplotlibDeprecationWarning: \n",
            "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
            "  \"Adding an axes using the same arguments as a previous axes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAD8CAYAAABJsn7AAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niBqwiEggasAiIoGoAYuIBKIGLCISyH+ouW1CiczG4gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 25 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B160xYuu4Bt8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}